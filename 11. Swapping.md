# Swapping
---
> 우리는 모든 것을 physical memory에 저장하고 싶지만, physical memory의 크기에는 한계가 있기 때문에     
> 지금 당장 사용하지 않는 address space를 어딘가에 저장해주어야 한다.      
> 그리고 이것을 __Memory Hierarchy__ 구조라고 한다.

![image](https://user-images.githubusercontent.com/80378041/165474478-0929bd87-3f11-4d26-b2b7-452f620dfda2.png)

## How to Swap
> 위쪽 계층에서 아래 계층으로 page를 swap하는 데는 3가지 방법이 있다.

- Overlays
  - 프로그래머가 직접 코드레벨에서 메모리를 관리하는 방법
- Process-level swapping
  - 프로세스 전체를 backing store에 옮기는 것
  - 보통 I/O Event를 기다릴 때 사용한다
- Page-level swapping
  - 지금 당장 필요없는 페이지를 내린다
  - swap-out : page를 backing store로 옮기는 것
  - swap-in : backing store에서 page를 가지고 오는 것

## Where to Swap
- Swap space
  - swap space의 크기가 사용할 수 있는 메모리 페이지의 최대 개수를 정해준다
  - 블럭 사이즈는 page 사이즈와 동일하다

![image](https://user-images.githubusercontent.com/80378041/165475482-18002cee-c1d0-4523-bd1c-ad51394af768.png)

## Single large address for a process
> 이러한 Swapping 방식은 각각의 process가 대용량의 메모리를 가지고 있다고 생각하게 해준다

## Present Bit
> Page가 physical memory 안에 있는지, 아니면 disk에 있는지를 구분하기 위해 사용하는 bit.      
> 1이면 physical memory 안에 존재하고, 0이면 disk에 존재한다

## Page Fault
> present bit가 0이면, 해당 페이지가 physical memory 안에 없는 것이기 때문에     
> OS가 페이지를 디스크에서 가져와야 한다.
 
 ![image](https://user-images.githubusercontent.com/80378041/165476152-93d1538a-7ae5-428e-bc2f-dc2e3c50514b.png)

## If Memory is Full
> 만약 메모리가 가득 찼으면, 임의의 Page를 메모리에서 쫒아내고, 새로운 Page를 가져와야 한다.      
> 하지만, 하나씩 계속 교체해주는 방법을 사용하게 되면, overhead가 많이 발생하게 되고,      
> 따라서 현실에서 하나씩 교체하는 방법을 사용하긴 힘들다.

### Swap Daemon, Page Daemon
> 그래서 나온 방법이 항상 일정 이상의 free 메모리 공간이 있도록 유지해주는 방법이다.     
> Low watermark 와 High watermark를 지정해주고, free page가 LW보다 작으면 memory에서 Page를 쫒아내고 공간을 확보한다.      
> 이 때, HW에 도달할 때까지 공간을 확보하게 된다.

### What to Swap
> 그렇다면, 어떤 페이지들을 쫒아낼 수 있을까?

![image](https://user-images.githubusercontent.com/80378041/165477121-b3cdc5bf-744b-4103-9a38-e0d1d9abe96c.png)

- Not swapped는 항상 메모리에 존재해야하기 때문에 Swap이 되지 않는다.
- Dropped는 Disk나 file system에 저장되어있는 경우에 Swap을 하지 않고 버려준다
- User에 의해 변경되어서 저장할 필요가 있을 때는 Swap을 해준다

## Policies
> 그렇다면, 누구를 쫒아낼 것인지에 대한 법칙도 필요해진다.      
> 보통 Cache Managment `P_hit * T_m + P_miss * T_d`가 가장 높게 나오는 방법을 선택하고 싶을 것이다.

### Optimal Replacement Policy
> 가장 먼 미래에 access되는 page를 쫒아내는 방법이다.      
> 이론적으로는 가장 miss가 적은 방법이지만, 미래를 알아야 하기 때문에 현실에서는 구현해낼 수 없다.     
> 다른 방법에 대한 비교 대상으로만 사용된다.

![image](https://user-images.githubusercontent.com/80378041/165478139-df9640a5-8337-41e9-9b0f-1587a2ae7934.png)

### FIFO(First In First Out)
> 먼저 메모리에 올라온 것을 쫒아내는 방법이다.     
> 중요한 block을 구분해서 쫒아낼 수 없는 단점이 있다.

![image](https://user-images.githubusercontent.com/80378041/165478395-9de2a26e-ba63-4492-bf8b-3b01db40e896.png)


### BELADY's ANOMALY
> 캐시의 크기를 키우면 Hit가 많아질 것이라고 생각하지만, miss가 많아지는 현상이다.     
> FIFO가 해당된다

![image](https://user-images.githubusercontent.com/80378041/165478700-9a033652-2e62-4030-a6ed-526f0c7930b7.png)

### Random
> 말 그대로 무작위로 쫒아내는 방법이다.     
> 운만 좋다면, Optimal과 동일한 성능을 낼 수도 있다.

## Using History
> 이제는, 과거를 보고 미래를 예측하는 방법들이다.     
> recency와 frequency정보를 보고 미래를 예측하는 2가지 방법이 있다

### LRU(Least Recently Used)
> 사용한지 가장 오래된 것을 쫒아내는 방법이다.

- temporal locality와 잘 맞는다
- BELADY's ANOMALY에 영향을 받지 않는다
- frequency는 고려하지 않는다
- 모든 workload에 적합한 것은 아니다
- 구현하기 어렵고, 완벽 구현은 사실상 불가능하다

![image](https://user-images.githubusercontent.com/80378041/165479399-16b37f1d-f62d-4504-a85c-806d83ca80b5.png)

